title:读书笔记之亿级流量网站架构核心技术（二）  
tags:[读书笔记]  
date:2017-9-18  

---  

### 应用级缓存 ###  
缓存的目的是让数据更接近使用者，让访问速度更快。工作机制是先从缓存中读取数据，如果没有，再从慢速设备上获取实际数据并同步到缓存。  

#### 缓存命中率 ####  
缓存命中率是从缓存中读取数据的次数与总读取次数的比率，命中率越高越好。  

#### 缓存回收策略 ####  
1. 基于空间  
2. 基于容量  
3. 基于时间  
3.1 TTL：存活期  
3.2 TTI：空闲期
4. 基于Java对象引用  
5. 回收算法  
5.1 FIFO:先进先出  
5.2 LRU:最近最少使用算法，使用时间距离现在最久的那个被移除。  
5.3 LFU:最不常用算法，一定时间内使用次数最少的那个被移除。  

#### Java缓存类型 ####  
**堆缓存**：使用Java堆内存来存储缓存对象。使用堆缓存的好处是没有序列化/反序列化，是最快的缓存。缺点也明显，当缓存的数据量很大时，GC时间会变长，存储容量受限于堆空间大小。一般通过弱引用/软引用来存储缓存对象，即当堆内存不足时，可以强制回收这部分内存释放对内存空间。一般使用堆缓存存储较热的数据。

**堆外缓存**：即缓存数据存储在堆外内存，可以减少GC暂停时间，可以支持更大的缓存空间（只收机器内存大小限制，不受堆空间的影响）。但是，读取数据是需要序列化/反序列化，因此会比堆缓存慢的多。  
磁盘缓存：即缓存数据存储在磁盘上，在JVM重启时数据还是存在的，而堆缓存/堆外缓存数据会丢失，需要重新加载。  

**分布式缓存**：上文提到的都是进程内缓存和磁盘缓存，在多JVM实例的情况下，会存在两个问题：1.单机容量问题；2.数据一致性问题（可以设置缓存的过期时间来定期更新数据）  
缓存不命中时，需要回源到DB/服务请求多变问题：每个实例在缓存不命中的情况下都会回源到DB加载数据，因此，多实例后DB整体的访问量就变多了，解决办法是可以使用如一致性哈希分片算法。因此，这些情况可以考虑使用分布式缓存来解决，可以使用ehcache-clustered实现Java进程间分布式缓存,当然也可以使用如Redis实现分布式缓存。  

<span style="color:red">Guava Cache只提供堆缓存，小巧灵活，性能最好，如果只使用堆缓存，那么使用它就够了。</span>  

#### 缓存使用模式 ####  
缓存模式总结好的有两大类：Cache-Aside和Cache-As-SoR(Read-through、Write-through、Write-behind)  
**名词解释**  
**SoR(system-of-record)**：记录系统，或者可以叫做数据源，即实际存储原始数据的系统。  
**Cache**: 缓存，是SoR的快照数据，Cache的访问速度比SoR更快，放入Cache的目的是提升访问速度，减少回源到SoR的次数。  

**Cache-Aside**  
Cache-Aside即业务代码围绕Cache写，是由业务代码直接维护缓存。  
对于Cache-Aside,可能存在并发更新情况，即多个应用实例同时更新，那么缓存怎么办？  
- 如果是用户维度的数据（如订单数据、用户数据）,这种几率非常小，因为并发的情况很少，可以不考虑这个问题，加上过期时间来解决即可。  
- 对于如商品这种基础数据，可以考虑使用canal订阅binlog,来进行增量更新分布式缓存，这样不会存在缓存数据不一致的情况，但是缓存更新会存在延迟。而本地缓存可根据不一致容忍度设置合理的过期时间。  
- 读服务场景，可以考虑使用一致性哈希，将相同的操作负载均衡到同一个实例。从而减少并发几率。或者设置比较短的过期时间。  

**Cache-As-SoR**  
Cache-As-SoR即把Cache看做SOR,所有操作都是堆Cache进行，然后Cache再委托给SoR进行真实的读/写。有三种实现：read-through、write-through、write-behind  
**Read-through**  
Read-through,业务代码首先调用Cache,如果Cache不命中由Cache回源到SoR，而不是业务代码。使用Read-through 模式需要配置一个CacheLoader组件用来回源到SoR加载源数据。  
使用CacheLoader由如下几个好处：  
应用业务代码更简洁了，不需要像Cache-Aside模式那样缓存查询代码和SoR代码交织在一起。如果缓存使用逻辑散落在多处，则使用这种方式很简单地消除了重复代码。  
解决Dog-pile effect，即当某个缓存失效时，又有大量相同的请求没命中缓存，从而使请求同时到后端，导致后端压力太大，此时限定一个请求去拿即可。  
**Write-through**  
Write-through,被称为穿透写模式/直写模式——业务代码首先调用Cache写数据，然后由Cache负责写缓存和写SoR,而不是由业务代码。需要配置CacheLoaderWriter  
**Write-behind**  
Write-Behind，回写模式。不同于Write-through是同步写SoR和Cache,Write-behind是异步写。异步之后可以实现批量写、合并写、延时和限流。  

### HTTP缓存 ###  
浏览器缓存是指我们使用浏览器访问一些网站页面或者HTTP服务时，根据服务端返回的缓存设置响应头将响应内容缓存到浏览器，下次可以直接使用缓存内容或者仅需要去服务器验证内容是否过期即可。这样的好处是可以减少浏览器和服务器端之间来回传输的数据量，节省带宽以提升性能。  
**Age**  
一般用于缓存代理层。表示此内容在缓存代理层从创建到现在生存了多长时间  
**Vary**  
一般用于缓存代理层，主要用于通知缓存服务器对于相同URL有着不同版本的响应。缓存服务器应该根据Vary头来缓存不同版本的内容。  
**Via**  
一般用于代理层，表示访问到最终内容前经过了哪些代理层，用的什么协议，代理层是否缓存命中等  
**ETag**  
ETag用于发送到服务端进行内容变更验证  

#### 总结 ####  
1. 服务器端响应的Lat-Modified会在下次请求时，将If-Modified-Since请求头带到服务器端进行文档是否修改的验证，如果没有修改则返回304，浏览器可以直接使用缓存内容。  
2. Cache-Control:max-age和Expires用于决定浏览器端内容缓存多久，即多久过期，过期后则删除缓存重新从服务器端获取最新的。  
3. HTTP/1.1规范定义的Cache-Control优先级高于HTTP/1.0规范定义的Expires。  
4. 一般情况下Expires=当前系统时间 + 缓存时间（Cache-Control:max-age）  
5. HTTP/1.1规范定义ETag为“被请求变量的实体值”，可简单理解为文档内容摘要，ETag可用来判断页面内容是否已经被修改过了。  
Last-Modified与ETag同时使用时，浏览器在验证时会同时发送If-Modified-Since和If-None-match。按照HTTP/1.1规范，如果同时使用If-Modified-Since和If-None-Match,则服务器端必须两个验证都通过后才能返回304，Nginx就是这样做的。  

### HttpClient客户端缓存 ###  
HttpClient请求流程如下：  
1. 检查HTTP请求是否符合HTTP/1.1规范，如果不符合，则会进行修正。  
2. 清除该请求中的无效请求头  
3. 检查该请求是否可以使用缓存内容，如果不能则发送请求到上游服务器获取最新内容。  
4. 如果该请求可以使用缓存内容作为响应，则尝试读取缓存中的缓存内容。如果读取失败，则同样发送请求到上游服务器获取最新内容。  
5. 如果缓存的相应内容可以使用，则会构建一个包含ByteArrayEntity的basicHttpRequest对象。否则，会向上有服务器发出重新验证缓存内容的请求。  
6. 如果缓存的响应内容向上游服务器验证失败，那么会重新向上游服务器发出一次不包含缓存头的请求来获取最新的内容  

HttpClient响应流程如下:  
1. 检查收到的响应是否兼容HTTP/1.1,如果不兼容，则会让其符合规范。  
2. 检查响应是否可以缓存，如果可以，则会从响应中读取内容体，并缓存起来。  
3. 如果响应数据太大，超过了配置的大小，则直接返回响应不进行缓存。  

### Nginx 缓存设置 ###  
Nginx HTTP缓存：Nginx提供了expires、etag、if-modified-since指令来是实现浏览器缓存控制  
Nginx 代理层缓存  

### 多级缓存 ###  
#### 分布式缓存与应用负载均衡 ####  
**缓存分布式**  
分布式缓存一般采用分片实现，即将数据分散到多个实例或多台服务器。  
算法一般采用取模和一致性哈希。要是采用不过期缓存机制，可以考虑取模。对于可丢失的缓存数据，可以考虑一致性哈希。  
**应用负载均衡**  
应用负载均衡一般采用轮询和一致性哈希，一致性哈希可以根据应用请求的URL或者URL参数将相同的请求转发到同一个节点。而轮询是将请求均匀地转发到每一个服务器  
轮询的优点是，到应用Nginx的请求更加均匀，使得每个服务器的负载基本均衡。轮询的缺点是，随着应用Nginx服务器的增加，缓存的命中率会下降。而这种方式不会因为热点问题导致其中一台服务器负载过重  
一致性哈希的优点是，相同请求都会转发到同一台服务器，命中率不会因为增加服务器而降低。一致性哈希的缺点是，因为相同的请求会转发到同一台服务器，因此可能造成某台服务器负载过重，甚至因为请求太多导致服务出现问题。  
解决办法是根据实际情况动态选择用哪种算法  
- 负载较低时，使用一致性哈希  
- 热点请求降级一致性哈希为轮询，或者如果请求数据有规律，则可以考虑带权重的一致性哈希  
- 将热点数据推送到接入层Nginx,直接响应给客户  

#### 热点数据与更新缓存 ####  
**热点数据**  
热点数据会造成服务器压力过大，导致服务器性能、吞吐量、带宽达到极限，出现响应慢或者拒绝服务的情况，有以下几种解决方式：  
1. 单机全量缓存+主从  
2. 分布式缓存+应用本地热点  
3. 建立实时热点发现系统  

**更新缓存与原子性**  
- 更新数据时使用更新时间戳或者版本比对，如果使用Redistribution，则可以利用其单线程机制进行原子化更新  
- 使用如canal订阅数据库binlog  
- 将更新请求按照相应的规则分散到多个队列，然后每个队列进行单线程更新，更新时拉去最新的数据保存  
- 用分布式锁，在更新之前获取相关的锁  

**缓存崩溃与快速修复**  
**取模**  
对于取模机制，如果其中一个实例坏了，摘除次失利将导致大量缓存不命中，则瞬时大流量可能导致后端DB/服务出现问题。主从机制避免问题  
**一致性哈希**  
对于一致性哈希，如果其中一个实力坏了，摘除此实例只影响一致性哈希上的部分缓存不命中，不会导致大量缓存瞬间回源到后端DB服务  
**快速恢复**  
- 主从机制  
- 部分用户降级，然后慢慢减少降级量，后台通过worker预热缓存数据  
